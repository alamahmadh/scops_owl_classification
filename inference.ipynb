{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1407079",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The code of this inference stage largely based on the code in\n",
    "https://github.com/johnmartinsson/bird-species-classification\n",
    "\n",
    "I demonstrate the testing for the dual input mode.\n",
    "'''\n",
    "\n",
    "from sklearn import metrics\n",
    "import skimage\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "\n",
    "import config\n",
    "#from models.resnet import ResNetBuilder\n",
    "from models.cnn import CNNBaseline, CNNDual\n",
    "\n",
    "def load_test_dual(directory, target_size, audio_mode1, audio_mode2):\n",
    "    if not os.path.isdir(directory):\n",
    "        raise ValueError(\"data filepath is invalid\")\n",
    "\n",
    "    classes = []\n",
    "    for subdir in sorted(os.listdir(directory)):\n",
    "        if os.path.isdir(os.path.join(directory, subdir)):\n",
    "            classes.append(subdir)\n",
    "    nb_classes = len(classes)\n",
    "    class_indices = dict(zip(classes, range(nb_classes)))\n",
    "    index_to_species = dict(zip(range(nb_classes), classes))\n",
    "\n",
    "    X_test1 = []\n",
    "    X_test2 = []\n",
    "    Y_test = []\n",
    "    training_files = []\n",
    "    for subdir in classes:\n",
    "        subpath = os.path.join(directory, subdir)\n",
    "        # load sound data\n",
    "        class_segments = glob.glob(os.path.join(subpath, \"*.wav\"))\n",
    "        # print(subdir+\": \", len(class_segments))\n",
    "        print(\"group segments ... \")\n",
    "        samples = group_segments(class_segments)\n",
    "        for sample in samples:\n",
    "            training_files.append(sample)\n",
    "            data1 = load_segments(sample, target_size, inputmode1)\n",
    "            data2 = load_segments(sample, target_size, inputmode2)\n",
    "            X_test1.append(data1)\n",
    "            X_test2.append(data2)\n",
    "            y = np.zeros(nb_classes)\n",
    "            y[class_indices[subdir]] = 1.0\n",
    "            Y_test.append(y)\n",
    "    return np.asarray(X_test1), np.asarray(X_test2), np.asarray(Y_test), training_files\n",
    "\n",
    "def load_test_single(directory, target_size, inputmode):\n",
    "    if not os.path.isdir(directory):\n",
    "        raise ValueError(\"data filepath is invalid\")\n",
    "\n",
    "    classes = []\n",
    "    for subdir in sorted(os.listdir(directory)):\n",
    "        if os.path.isdir(os.path.join(directory, subdir)):\n",
    "            classes.append(subdir)\n",
    "    nb_classes = len(classes)\n",
    "    class_indices = dict(zip(classes, range(nb_classes)))\n",
    "    index_to_species = dict(zip(range(nb_classes), classes))\n",
    "\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "    training_files = []\n",
    "    for subdir in classes:\n",
    "        subpath = os.path.join(directory, subdir)\n",
    "        # load sound data\n",
    "        class_segments = glob.glob(os.path.join(subpath, \"*.wav\"))\n",
    "        # print(subdir+\": \", len(class_segments))\n",
    "        print(\"group segments ... \")\n",
    "        samples = group_segments(class_segments)\n",
    "        for sample in samples:\n",
    "            training_files.append(sample)\n",
    "            data = load_segments(sample, target_size, inputmode)\n",
    "            X_test.append(data)\n",
    "            y = np.zeros(nb_classes)\n",
    "            y[class_indices[subdir]] = 1.0\n",
    "            Y_test.append(y)\n",
    "    return np.asarray(X_test), np.asarray(Y_test), training_files\n",
    "\n",
    "def load_segments(segments, target_size, input_data_mode):\n",
    "    print(segments, target_size, input_data_mode)\n",
    "    data = []\n",
    "    for segment in segments:\n",
    "        (fs, signal) = utils.read_wave_file(segment)\n",
    "        if input_data_mode == \"mfcc\":\n",
    "            sample = librosa.feature.mfcc(signal, fs, n_mfcc=target_size[0])\n",
    "            sample = skimage.transform.resize(sample, target_size)\n",
    "            sample = sample.reshape((sample.shape[0],\n",
    "                                     sample.shape[1], 1))\n",
    "        if input_data_mode == \"mfcc_delta\":\n",
    "            mfcc = librosa.feature.mfcc(signal, fs, n_mfcc=target_size[0])\n",
    "            mfcc_delta_3 = librosa.feature.delta(mfcc, width=3, order=1)\n",
    "            mfcc_delta_11 = librosa.feature.delta(mfcc, width=11, order=1)\n",
    "            mfcc_delta_19 = librosa.feature.delta(mfcc, width=19, order=1)\n",
    "\n",
    "            mfcc = skimage.transform.resize(mfcc, target_size)\n",
    "            mfcc_delta_3 = skimage.transform.resize(mfcc_delta_3, target_size)\n",
    "            mfcc_delta_11 = skimage.transform.resize(mfcc_delta_11, target_size)\n",
    "            mfcc_delta_19 = skimage.transform.resize(mfcc_delta_19, target_size)\n",
    "\n",
    "            mfcc = mfcc[0:mfcc.shape[0], 0:mfcc.shape[1], 0:1]\n",
    "            mfcc_delta_3 = mfcc_delta_3[0:mfcc_delta_3.shape[0], 0:mfcc_delta_3.shape[1], 0:1]\n",
    "            mfcc_delta_11 = mfcc_delta_11[0:mfcc_delta_11.shape[0], 0:mfcc_delta_11.shape[1], 0:1]\n",
    "            mfcc_delta_19 = mfcc_delta_19[0:mfcc_delta_19.shape[0], 0:mfcc_delta_19.shape[1], 0:1]\n",
    "            sample = np.concatenate([mfcc, mfcc_delta_3, mfcc_delta_11, mfcc_delta_19], axis=2)\n",
    "\n",
    "        if input_data_mode == \"spectrogram\":\n",
    "            sample = wave_to_sample_spectrogram(signal, fs)\n",
    "            sample = skimage.transform.resize(sample, target_size)\n",
    "            sample = sample.reshape((sample.shape[0], sample.shape[1], 1))\n",
    "        \n",
    "        if input_data_mode == \"melspectrogram\":\n",
    "            # Han window of size 512, and hop size 128 (75% overlap)\n",
    "            #spect = wave_to_sample_spectrogram(wave, fs)\n",
    "            # Passing through arguments to the Mel filters\n",
    "            sample = librosa.feature.melspectrogram(signal, fs)\n",
    "            #mel = librosa.feature.melspectrogram(S=spect, sr=fs)\n",
    "            sample = librosa.power_to_db(sample)\n",
    "            sample = skimage.transform.resize(sample, target_size)\n",
    "            sample = sample.reshape((sample.shape[0], sample.shape[1], 1))\n",
    "            \n",
    "        data.append(sample)\n",
    "\n",
    "    return np.asarray(data)\n",
    "\n",
    "def group_segments(segments):\n",
    "    unique_samples = []\n",
    "    for segment in segments:\n",
    "        splits = segment.split('_')\n",
    "        if not splits[2] in unique_samples:\n",
    "            unique_samples.append(splits[2])\n",
    "\n",
    "    samples = []\n",
    "    for unique_sample in unique_samples:\n",
    "        sample = []\n",
    "        for segment in segments:\n",
    "            if segment.split('_')[2] == unique_sample:\n",
    "                sample.append(segment)\n",
    "        # print(unique_sample, \":\", len(sample))\n",
    "        samples.append(sample)\n",
    "    return samples\n",
    "\n",
    "def average_prediction(modelx, X1, X2):\n",
    "    y_scores = modelx.predict([X1,X2])\n",
    "    y_average_score = np.mean(y_scores, axis=0)\n",
    "    return y_average_score\n",
    "\n",
    "def average_prediction0(modelx, X):\n",
    "    y_scores = modelx.predict(X)\n",
    "    y_average_score = np.mean(y_scores, axis=0)\n",
    "    return y_average_score\n",
    "\n",
    "def mean_average_precision(y_trues, y_scores):\n",
    "    \"\"\"\n",
    "    y_trues  : [nb_samples, nb_classes]\n",
    "    y_scores : [nb_samples, nb_classes]\n",
    "    map      : float (MAP)\n",
    "    \"\"\"\n",
    "    aps = []\n",
    "    for y_t, y_s in zip(y_trues, y_scores):\n",
    "        ap = metrics.average_precision_score(y_t, y_s)\n",
    "        aps.append(ap)\n",
    "    return np.mean(np.array(aps))\n",
    "\n",
    "    \n",
    "model_name = config.model_name\n",
    "print(\"loading model {} ... \".format(model_name))\n",
    "    \n",
    "model = None\n",
    "if model_name == 'cnn_baseline':\n",
    "    model = CNNBaseline(nb_classes, input_shape)\n",
    "elif model_name == 'cnn_dual':\n",
    "    model = CNNDual(nb_classes, input_shape1, input_shape2)\n",
    "elif model_name == 'resnet_18':\n",
    "    model = ResNetBuilder.build_resnet_18(input_shape, nb_classes)\n",
    "elif model_name == 'resnet_34':\n",
    "    model = ResNetBuilder.build_resnet_34(input_shape, nb_classes)\n",
    "elif model_name == 'resnet_50':\n",
    "    model = ResNetBuilder.build_resnet_50(input_shape, nb_classes)\n",
    "elif model_name == 'resnet_101':\n",
    "    model = ResNetBuilder.build_resnet_101(input_shape, nb_classes)\n",
    "elif model_name == 'resnet_152':\n",
    "    model = ResNetBuilder.build_resnet_152(input_shape, nb_classes)\n",
    "else:\n",
    "    raise ValueError(\"Can not find model \", model_name, \".\")\n",
    "\n",
    "model.load_weights(config.best_weight_file_path)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=config.optimizer)\n",
    "\n",
    "print(\"loading test data ... \")\n",
    "if inputmode=='dual':\n",
    "    (X_tests1, X_tests2 Y_tests, training_files) = load_test_dual(config.test_path, \n",
    "                                                                  config.target_size, \n",
    "                                                                  config.audio_mode1,\n",
    "                                                                  config.audio_mode2)\n",
    "        \n",
    "y_scores = []\n",
    "y_trues = Y_tests\n",
    "print(\"running predictions ... \")\n",
    "for X_t1,X_t2 in zip(X_tests1,X_tests2):\n",
    "    y_score = average_prediction(model, X_t1,X_t2)\n",
    "    y_scores.append(y_score)\n",
    "\n",
    "print(mean_average_precision(y_trues, y_scores))\n",
    "    \n",
    "y_preds = np.argmax(y_scores,axis=1)\n",
    "y_tests = np.argmax(Y_tests,axis=1)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_tests, y_preds))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(y_tests, y_preds, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f5bc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#An example of the mel-spectrogram visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import librosa\n",
    "\n",
    "fname = 'data/test/ Otus_angelinae/Otusangelinae141909-extract3.wav'\n",
    "y, sr = librosa.load(fname)\n",
    "S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
    "plt.figure(figsize=(20, 5))\n",
    "S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "librosa.display.specshow(S_dB, x_axis='time',\n",
    "                          y_axis='mel', sr=sr)\n",
    "#plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel-frequency spectrogram')\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
